import cv2
import numpy as np
import imutils
from imutils import contours
from flask import Flask, request, jsonify
from flask_cors import CORS
import logging

# --- SETUP ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("OMR_Human_Eye")
app = Flask(__name__)
CORS(app)

# --- HUMAN EYE CLASS (à¤†à¤‚à¤–) ---
class HumanEye:
    def load_image(self, file_bytes) -> np.ndarray:
        try:
            nparr = np.frombuffer(file_bytes, np.uint8)
            return cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        except:
            return None

    def adjust_vision(self, img):
        """
        à¤†à¤‚à¤– à¤•à¥€ à¤ªà¥à¤¤à¤²à¥€ à¤•à¥€ à¤¤à¤°à¤¹ à¤°à¥Œà¤¶à¤¨à¥€ à¤¸à¥‡à¤Ÿ à¤•à¤°à¤¨à¤¾ (Adaptive Vision)
        """
        # 1. à¤—à¥à¤°à¥‡à¤¸à¥à¤•à¥‡à¤² à¤®à¥‡à¤‚ à¤¬à¤¦à¤²à¥‹
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # 2. CONTRAST BOOST (à¤¨à¥€à¤²à¥‡ à¤ªà¥‡à¤¨ à¤•à¥‹ à¤—à¤¹à¤°à¤¾ à¤•à¤¾à¤²à¤¾ à¤¬à¤¨à¤¾à¤¨à¤¾)
        # à¤¯à¤¹ à¤¦à¥‡à¤–à¥‡à¤—à¤¾ à¤•à¤¿ à¤‡à¤®à¥‡à¤œ à¤®à¥‡à¤‚ à¤¸à¤¬à¤¸à¥‡ à¤¡à¤¾à¤°à¥à¤• à¤”à¤° à¤²à¤¾à¤‡à¤Ÿ à¤ªà¤¿à¤•à¥à¤¸à¥‡à¤² à¤•à¥Œà¤¨ à¤¸à¥‡ à¤¹à¥ˆà¤‚ à¤”à¤° à¤‰à¤¨à¥à¤¹à¥‡à¤‚ à¤«à¥ˆà¤²à¤¾ à¤¦à¥‡à¤—à¤¾
        gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)

        # 3. ADAPTIVE THRESHOLD (à¤›à¤¾à¤¯à¤¾/Shadow à¤¹à¤Ÿà¤¾à¤¨à¤¾)
        # à¤¯à¤¹ à¤¹à¤° à¤›à¥‹à¤Ÿà¥‡ à¤¹à¤¿à¤¸à¥à¤¸à¥‡ (21x21 block) à¤•à¥‹ à¤…à¤²à¤—-à¤…à¤²à¤— à¤šà¥‡à¤• à¤•à¤°à¥‡à¤—à¤¾
        # 15 = Constant (Noise à¤¹à¤Ÿà¤¾à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤)
        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                     cv2.THRESH_BINARY_INV, 21, 10)

        return gray, thresh

    def four_point_transform(self, image, pts):
        # à¤‡à¤®à¥‡à¤œ à¤•à¥‹ à¤¸à¥€à¤§à¤¾ à¤•à¤°à¤¨à¤¾ (Perspective Transform)
        rect = np.zeros((4, 2), dtype="float32")
        s = pts.sum(axis=1)
        rect[0] = pts[np.argmin(s)]
        rect[2] = pts[np.argmax(s)]
        diff = np.diff(pts, axis=1)
        rect[1] = pts[np.argmin(diff)]
        rect[3] = pts[np.argmax(diff)]
        (tl, tr, br, bl) = rect
        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
        maxWidth = max(int(widthA), int(widthB))
        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
        maxHeight = max(int(heightA), int(heightB))
        dst = np.array([[0, 0], [maxWidth - 1, 0], [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]], dtype="float32")
        M = cv2.getPerspectiveTransform(rect, dst)
        return cv2.warpPerspective(image, M, (maxWidth, maxHeight))

# --- HUMAN BRAIN CLASS (à¤¦à¤¿à¤®à¤¾à¤—) ---
class HumanBrain:
    def __init__(self):
        self.eye = HumanEye()

    def think(self, img_bytes):
        # 1. à¤†à¤‚à¤– à¤¸à¥‡ à¤¦à¥‡à¤–à¥‹
        img = self.eye.load_image(img_bytes)
        if img is None: return {"error": "Image Load Failed"}

        # 2. à¤µà¤¿à¤œà¤¨ à¤à¤¡à¤œà¤¸à¥à¤Ÿ à¤•à¤°à¥‹ (Shadow & Blue Pen Logic)
        gray, thresh = self.eye.adjust_vision(img)

        # 3. à¤ªà¥‡à¤ªà¤° à¤•à¤¾ à¤¬à¥‰à¤°à¥à¤¡à¤° à¤¢à¥‚à¤à¤¢à¥‹
        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cnts = imutils.grab_contours(cnts)
        docCnt = None
        
        if len(cnts) > 0:
            cnts = sorted(cnts, key=cv2.contourArea, reverse=True)
            for c in cnts:
                peri = cv2.arcLength(c, True)
                approx = cv2.approxPolyDP(c, 0.02 * peri, True)
                if len(approx) == 4:
                    docCnt = approx
                    break
        
        if docCnt is not None:
            warped = self.eye.four_point_transform(gray, docCnt.reshape(4, 2))
            thresh_warped = self.eye.four_point_transform(thresh, docCnt.reshape(4, 2))
        else:
            warped = gray
            thresh_warped = thresh

        # 4. à¤—à¥‹à¤²à¥‡ à¤¢à¥‚à¤à¤¢à¥‹ (Universal Bubble Hunting)
        cnts = cv2.findContours(thresh_warped.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cnts = imutils.grab_contours(cnts)
        
        questionCnts = []
        for c in cnts:
            (x, y, w, h) = cv2.boundingRect(c)
            ar = w / float(h)
            # à¤«à¤¿à¤²à¥à¤Ÿà¤°: à¤¯à¥‚à¤¨à¤¿à¤µà¤°à¥à¤¸à¤² à¤¸à¤¾à¤‡à¤œ (à¤›à¥‹à¤Ÿà¤¾ à¤—à¥‹à¤²à¤¾ à¤­à¥€ à¤”à¤° à¤¬à¤¡à¤¼à¤¾ à¤­à¥€)
            if w >= 16 and h >= 16 and ar >= 0.75 and ar <= 1.25:
                questionCnts.append(c)

        if not questionCnts:
            return {"status": "error", "message": "No bubbles found."}

        # 5. Sorting (à¤ªà¤¹à¤²à¥‡ à¤Šà¤ªà¤° à¤¸à¥‡ à¤¨à¥€à¤šà¥‡, à¤«à¤¿à¤° à¤•à¥‰à¤²à¤®)
        questionCnts = contours.sort_contours(questionCnts, method="top-to-bottom")[0]
        
        # 4 à¤•à¥‰à¤²à¤® (Aryabhatta Pattern)
        bbs = [cv2.boundingRect(c) for c in questionCnts]
        zipped = sorted(zip(bbs, questionCnts), key=lambda b: b[0][0]) 
        total_cols = 4
        bubbles_per_col = len(zipped) // total_cols
        
        results = {}
        options_map = ['A', 'B', 'C', 'D']
        q_num = 1

        for col_i in range(total_cols):
            col_bubbles = zipped[col_i * bubbles_per_col : (col_i + 1) * bubbles_per_col]
            col_bubbles = sorted(col_bubbles, key=lambda b: b[0][1])

            # 4-4 à¤•à¤¾ à¤—à¥à¤°à¥à¤ª (Question)
            for i in range(0, len(col_bubbles), 4):
                q_pack = col_bubbles[i:i+4]
                q_pack = sorted(q_pack, key=lambda b: b[0][0]) # A,B,C,D
                
                # --- PIXEL COMPARISON (Relative Logic) ---
                # à¤¹à¤® "Threshold" à¤¨à¤¹à¥€à¤‚, "Comparison" à¤•à¤°à¥‡à¤‚à¤—à¥‡ (à¤•à¥Œà¤¨ à¤¸à¤¬à¤¸à¥‡ à¤œà¥à¤¯à¤¾à¤¦à¤¾ à¤­à¤°à¤¾ à¤¹à¥ˆ)
                pixels = []
                for (bbox, c) in q_pack:
                    mask = np.zeros(thresh_warped.shape, dtype="uint8")
                    cv2.drawContours(mask, [c], -1, 255, -1)
                    mask = cv2.bitwise_and(thresh_warped, thresh_warped, mask=mask)
                    total = cv2.countNonZero(mask)
                    pixels.append(total)
                
                # à¤µà¤¿à¤¨à¤° à¤¢à¥‚à¤à¤¢à¥‹ (Winner Takes All)
                max_pixels = max(pixels)
                max_index = pixels.index(max_pixels)
                
                detected = "SKIP"
                
                # Logic: à¤•à¥à¤¯à¤¾ à¤µà¤¿à¤¨à¤° à¤•à¥‡ à¤ªà¤¾à¤¸ à¤•à¤® à¤¸à¥‡ à¤•à¤® à¤•à¥à¤› à¤¸à¥à¤¯à¤¾à¤¹à¥€ à¤¹à¥ˆ? (Noise Filter)
                # 300 à¤ªà¤¿à¤•à¥à¤¸à¥‡à¤² = à¤¬à¤¹à¥à¤¤ à¤¹à¤²à¥à¤•à¥€ à¤¸à¥à¤¯à¤¾à¤¹à¥€ à¤­à¥€ à¤šà¤²à¥‡à¤—à¥€
                if max_pixels > 300: 
                    detected = options_map[max_index]
                    
                    # Dual Check: à¤•à¥à¤¯à¤¾ à¤¦à¥‚à¤¸à¤°à¤¾ à¤¨à¤‚à¤¬à¤° à¤µà¤¾à¤²à¤¾ à¤­à¥€ à¤µà¤¿à¤¨à¤° à¤•à¥‡ à¤•à¤°à¥€à¤¬ à¤¹à¥ˆ?
                    sorted_p = sorted(pixels, reverse=True)
                    second_max = sorted_p[1]
                    
                    # à¤…à¤—à¤° à¤¦à¥‚à¤¸à¤°à¤¾ à¤—à¥‹à¤²à¤¾ à¤ªà¤¹à¤²à¥‡ à¤—à¥‹à¤²à¥‡ à¤•à¥‡ 90% à¤œà¤¿à¤¤à¤¨à¤¾ à¤­à¤°à¤¾ à¤¹à¥ˆ, à¤¤à¥‹ à¤¡à¥à¤…à¤² à¤¹à¥ˆ
                    if second_max > (max_pixels * 0.9): 
                        detected = "DUAL"

                results[str(q_num)] = detected
                q_num += 1

        return {"status": "success", "data": results}

# --- ROUTES ---
brain = HumanBrain()

@app.route('/')
def home(): return "Human-Like OMR Vision Active ğŸ‘ï¸ğŸ§ "

@app.route('/scan', methods=['POST'])
def scan():
    if 'file' not in request.files: return jsonify({"error": "No file"}), 400
    try:
        res = brain.think(request.files['file'].read())
        return jsonify(res)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run()
